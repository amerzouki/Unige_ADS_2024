{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üß¨ Clustering de cellules canc√©reuses\n",
    "Nous allons utiliser des m√©thodes de r√©duction de dimension (PCA) et de clustering (k-means) afin de regrouper des cellules canc√©reuses (issues de sous-types de cancer distincts) en fonction de leur expression g√©nique. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üíæ Donn√©es\n",
    "\n",
    "> L'ensemble de donn√©e (dataset) que nous allons utiliser contient les valeurs d'expression g√©nique de cellules canc√©reuses. Ces donn√©es sont extraites d'un manuscrit r√©dig√© par les chercheurs du projet d'analyse pan-canc√©reuse The Cancer Genome Atlas (TCGA).\n",
    " \n",
    "> Il y a 881 √©chantillons (lignes) repr√©sentant 5 sous-types de cancer distincts. Chaque √©chantillon comporte les valeurs d'expression g√©nique pour 20 531 g√®nes (colonnes). L'ensemble de donn√©es est disponible sur le UC Irvine Machine Learning Repository."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üì§ Import des Librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "import urllib\n",
    "\n",
    "import pandas as pd # Analyse et manipulation de donn√©es (utilisation des Panda DataFrame) https://pandas.pydata.org/docs/user_guide/index.html and/or https://sparkbyexamples.com/python-pandas-tutorial-for-beginners/ \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns # Visualization de donn√©es\n",
    "#import hvplot.pandas # Plots interactifs https://hvplot.holoviz.org/\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score, adjusted_rand_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# T√©l√©chargement et extraction du dataset\n",
    "\n",
    "Vous pouvez √©galement t√©l√©chager manuellement les fichiers de donn√©es depuis: https://archive.ics.uci.edu/dataset/401/gene+expression+cancer+rna+seq \n",
    "\n",
    "L'archive t√©l√©charg√©e devra alors √™tre d√©-zipp√©e et enregistr√©e dans le dossier courrant: **Unige_ml/Day_1_TP_2_Clustering**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uci_tcga_url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00401/\"\n",
    "archive_name = \"TCGA-PANCAN-HiSeq-801x20531.tar.gz\"\n",
    "\n",
    "# URL\n",
    "full_download_url = urllib.parse.urljoin(uci_tcga_url, archive_name)\n",
    "\n",
    "# T√©l√©charger le fichier\n",
    "r = urllib.request.urlretrieve (full_download_url, archive_name)\n",
    "\n",
    "# Extraire les donn√©es de l'archive\n",
    "tar = tarfile.open(archive_name, \"r:gz\")\n",
    "tar.extractall()\n",
    "tar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datafile = \"TCGA-PANCAN-HiSeq-801x20531/data.csv\"\n",
    "labels_file = \"TCGA-PANCAN-HiSeq-801x20531/labels.csv\"\n",
    "\n",
    "# Charger les donn√©es du fichier 'datafile'\n",
    "data = np.genfromtxt(\n",
    "    datafile,\n",
    "    delimiter=\",\",\n",
    "    usecols=range(1, 20532),\n",
    "    skip_header=1\n",
    ")\n",
    "\n",
    "# Charger les √©tiquettes du fichier 'labels_file'\n",
    "true_label_names = np.genfromtxt(\n",
    "    labels_file,\n",
    "    delimiter=\",\",\n",
    "    usecols=(1,),\n",
    "    skip_header=1,\n",
    "    dtype=\"str\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "V√©rifions la taille des donn√©es; i.e.,\n",
    "- Nombre d'√©chantillons (Nombre de lignes)\n",
    "- Nombre de g√®nes (Nombre de colonnes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Instruction**: V√©rifiez que le nombre d'√©tiquettes est consitent avec le nombre d'√©chantillons\n",
    "\n",
    "<details>\n",
    "<summary>Aide</summary>\n",
    "\n",
    "1) <a href=\"https://numpy.org/doc/stable/reference/generated/numpy.shape.html\">Utilisez numpy.shape</a>\n",
    "\n",
    "2) Les √©tiquettes sont dans `true_label_names`\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code ici\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consultons les premi√®res lignes et colonnes des donn√©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[:5,:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**instruction** Consultez les √©tiquettes des 5 premiers √©chantillons\n",
    "\n",
    "<details>\n",
    "<summary>Aide</summary>\n",
    "Ce sont les 5 premiers √©l√©ments de `true_label_names`\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code ici\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Valeurs uniques dans le tableau des √©tiquettes de r√©f√©rence\n",
    "np.unique(true_label_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convertir les abr√©viations en entiers avec LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode les √©tiquettes avec des valeurs entre 0 et le nombre de classes\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "true_labels = label_encoder.fit_transform(true_label_names)\n",
    "true_labels[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# √âtant donn√© que l'encodeur a √©t√© ajust√© aux donn√©es, vous pouvez voir les classes uniques repr√©sent√©es en utilisant .classes_.label_encoder.classes_\n",
    "label_encoder.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Instruction**: Fixer le nombre de clusters aux nombres de classes uniques repr√©sent√©es\n",
    "<details>\n",
    "<summary>Aide</summary>\n",
    "Vous pouvez utiliser la fonction \n",
    "<a href=\"https://www.w3schools.com/python/ref_func_len.asp\">`len(...)`</a>\n",
    " \n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code ici\n",
    "n_clusters = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Pipeline\n",
    "## Pipeline pour traiter les donn√©es"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Instruction**: Fixez le nombre de composantes principales √† 2 pour la m√©thode PCA\n",
    "<details>\n",
    "<summary>Aide</summary>\n",
    "Indiquez l'argument `n_components`\n",
    "\n",
    "Voir <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html\">Documentation PCA</a>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalisation et r√©duction de dimension\n",
    "preprocessor = Pipeline(\n",
    "    [\n",
    "        (\"scaler\", MinMaxScaler()),\n",
    "        # Code ici\n",
    "        (\"pca\", PCA(None,random_state=42))\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline pour effectuer le clustering K-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusterer = Pipeline(\n",
    "   [\n",
    "       (\n",
    "           \"kmeans\",\n",
    "           KMeans(\n",
    "               n_clusters=n_clusters,\n",
    "               init=\"k-means++\",\n",
    "               n_init=50,\n",
    "               max_iter=500,\n",
    "               random_state=42,\n",
    "           ),\n",
    "       ),\n",
    "   ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encha√Æner les pipelines de pr√©traitement et de clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline(\n",
    "    [\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"clusterer\", clusterer)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appliquer les √©tapes du pipeline sur les donn√©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# V√©rifie le r√©sultat de la r√©duction de dimension (Transformation en 2D)\n",
    "preprocessed_data = pipe[\"preprocessor\"].transform(data)\n",
    "preprocessed_data[:5,:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# V√©rifie le r√©sultat du clustering\n",
    "predicted_labels = pipe[\"clusterer\"][\"kmeans\"].labels_\n",
    "print(predicted_labels.shape)\n",
    "print(predicted_labels[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# √âvaluer la qualit√© du clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Instruction**: Calculez le coefficient de silhouette en fonction des donn√©es r√©duites `preprocessed_data` et des clusters attribu√©s `predicted_labels` \n",
    "<details>\n",
    "<summary>Aide</summary>\n",
    "Utilisez la fonction \n",
    "<a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.metrics.silhouette_score.html\">`silhouette_score(...)`</a>\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code ici\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Profitons d'avoir les √©tiquettes de r√©f√©rence pour calculer une deuxi√®me mesure de qualit√© du clustering :) \n",
    "\n",
    "**Instruction**: Calculez l'Indice de Rand Ajust√© (ARI) en fonction des √©tiquettes de r√©f√©rence `true_labels` et des clusters attribu√©s `predicted_labels` \n",
    "<details>\n",
    "<summary>Aide</summary>\n",
    "Utilisez la fonction \n",
    "<a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.metrics.adjusted_rand_score.html\">`adjusted_rand_score(...)`</a>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code ici\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualiser les donn√©es dans le contexte des √©tiquettes r√©elles et des √©tiquettes pr√©dites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construit le dataframe avec la projection des donn√©es en 2D, leurs clusters pr√©dits, et leurs √©tiquettes de r√©f√©rence\n",
    "pcadf = pd.DataFrame(\n",
    "    pipe[\"preprocessor\"].transform(data)[:,:2],\n",
    "    columns=[\"component_1\", \"component_2\"],\n",
    ")\n",
    "\n",
    "pcadf[\"predicted_cluster\"] = pipe[\"clusterer\"][\"kmeans\"].labels_\n",
    "pcadf[\"true_label\"] = label_encoder.inverse_transform(true_labels)\n",
    "pcadf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "plt.style.use(\"fivethirtyeight\")\n",
    "plt.figure(figsize=(8, 8))\n",
    "\n",
    "scat = sns.scatterplot(\n",
    "    data=pcadf,\n",
    "    x = \"component_1\",\n",
    "    y = \"component_2\",\n",
    "    s=50,\n",
    "    hue=\"predicted_cluster\",\n",
    "    style=\"true_label\",\n",
    "    palette=\"Set2\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**QUESTION:** \n",
    "- Comparez les clusters/√©tiquettes pr√©dites (couleurs) et les √©tiquettes r√©elles (formes)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# R√©glage des param√®tres\n",
    "Et si nous ne connaissions pas les √©tiquettes r√©elles des donn√©es...\n",
    "\n",
    "1) __Comment aurions-nous pu \"trouver\" le nombre de clusters (2, 5 ou 20 types de cellules)?__\n",
    "\n",
    "2) __Pourquoi baser le clustering sur 2 dimensions seulement? Pourrions-nous obtenir de meilleurs r√©sultats avec davantage de dimensions/composantes?__\n",
    "\n",
    "## R√©duction de dimension\n",
    "Utilisez les la variance expliqu√©e cumul√©e pour identifier le nombre appropri√© de composantes principales √† garder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# R√©cup√©re et visualise la variance expliqu√©e cumul√©e par les 20 premi√®res composantes\n",
    "m = 20\n",
    "pipe[\"preprocessor\"][\"pca\"].n_components = m\n",
    "pipe.fit(data)\n",
    "pipe[\"preprocessor\"][\"pca\"].explained_variance_\n",
    "plt.plot(\n",
    "    range(1, m+1),\n",
    "    np.cumsum(pipe[\"preprocessor\"][\"pca\"].explained_variance_ratio_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**QUESTION:**\n",
    "\n",
    "A partir d''un certain nombre de composantes principales, le gain en terme de variance expliqu√©e devient moindre.\n",
    "\n",
    "- A combien estimez-vous ce nombre (de composantes principales)?\n",
    "\n",
    "N'h√©sitez pas √† tester dans la suite du code diff√©rentes valeurs pour le nombre de composantes principales √† garder/utiliser et √©valuer l'impact sur le clustering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering\n",
    "Enfin, utilisons les m√©triques de qualit√© de clustering pour d√©finir le nombre clusters\n",
    "\n",
    "**Instruction**: \n",
    "- Fixez le nombre de composantes principales `n_components` √† 7\n",
    "- Faites varier le nombre de clusters `n_clusters` de 2 √† 10\n",
    "<details>\n",
    "<summary>Aide</summary>\n",
    "\n",
    "- Vous pouvez acc√©der aux hyperparam√®tre de la PCA, √† travers `pipe[\"preprocessor\"][\"pca\"]`\n",
    "\n",
    "- Vous pouvez acc√©der aux hyperparam√®tre de K-means clustering, √† travers `pipe[\"clusterer\"][\"kmeans\"]`\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listes vides pour stocker les m√©triques de qualit√© \n",
    "# Silhouette\n",
    "silhouette_scores = []\n",
    "# Index Rand Ajust√©\n",
    "ari_scores = []\n",
    "for n in range(2, 11):\n",
    "    # Faites varier le nombre de clusters,\n",
    "    # et laissez le nombre de composantes principales fix√© √† 7\n",
    "    ### Code ici - D√©but ###\n",
    "    \n",
    "    \n",
    "    ### Code ici - Fin ###\n",
    "    pipe.fit(data)\n",
    "\n",
    "    silhouette_coef = silhouette_score(\n",
    "        pipe[\"preprocessor\"].transform(data),\n",
    "        pipe[\"clusterer\"][\"kmeans\"].labels_,\n",
    "    )\n",
    "    ari = adjusted_rand_score(\n",
    "        true_labels,\n",
    "        pipe[\"clusterer\"][\"kmeans\"].labels_,\n",
    "    )\n",
    "\n",
    "    # Ajoute les m√©triques aux listes correspondantes\n",
    "    silhouette_scores.append(silhouette_coef)\n",
    "    ari_scores.append(ari)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualisez la relation entre le nombre de clusters et la qualit√© du clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use(\"fivethirtyeight\")\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.plot(\n",
    "    range(2, 11),\n",
    "    silhouette_scores,\n",
    "    c=\"#008fd5\",\n",
    "    label=\"Silhouette Coefficient\",\n",
    ")\n",
    "plt.plot(range(2, 11), ari_scores, c=\"#fc4f30\", label=\"ARI\")\n",
    "\n",
    "plt.xlabel(\"n_clusters\")\n",
    "plt.legend()\n",
    "plt.title(\"Clustering Performance as a Function of n_clusters\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# üìù R√©sum√©\n",
    "Dans ce notebook, vous avez utilis√© des m√©thodes de dimension de r√©duction et de clustering pour le regroupement automatique de cellules canc√©reuses.\n",
    "\n",
    "Vous avez couvert les aspects suivants:\n",
    "> - Le mod√®le de r√©duction de dimension PCA\n",
    "> - Le mod√®le de clustering K-means\n",
    "> - L'exploration et la pr√©paration des donn√©es avant leur utilisation pour la r√©duction de dimension et le clustering\n",
    "> - L'entrainement des deux mod√®les PCA et K-means\n",
    "> - L'exploration des hyperparam√®tres des deux mod√®les, i.e., nombre de composantes principales, et nombre de clusters\n",
    "> - L'√©valuation de la qualit√© du clustering √† l'aide du coefficient Silhouette et Score de Rand Ajust√© \n",
    "\n",
    "\n",
    "# üîó References:\n",
    "- [Scikit-learn library - Clustering](https://scikit-learn.org/stable/modules/clustering.html)\n",
    "- [K-Means Clustering in Python: A Practical Guide](https://realpython.com/k-means-clustering-python/)\n",
    "- [How to Select the Best Number of Principal Components for the Dataset](https://towardsdatascience.com/how-to-select-the-best-number-of-principal-components-for-the-dataset-287e64b14c6d)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
